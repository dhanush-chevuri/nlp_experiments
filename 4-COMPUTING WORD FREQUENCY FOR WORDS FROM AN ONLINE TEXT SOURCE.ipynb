{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6257,"status":"ok","timestamp":1731776210699,"user":{"displayName":"Lalith Srinivas","userId":"11769043678043727988"},"user_tz":-330},"id":"YLQJc2Wv43-q","outputId":"232c1e7c-6695-4aa0-d3e9-707de406dce4"},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (2.32.3)\n","Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (4.12.3)\n","Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.9.1)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests) (3.4.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests) (2.2.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests) (2024.8.30)\n","Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4) (2.6)\n","Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.4.2)\n","Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2024.9.11)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.6)\n"]}],"source":["pip install requests beautifulsoup4 nltk\n"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PDQyy14w53gZ","executionInfo":{"status":"ok","timestamp":1731776742153,"user_tz":-330,"elapsed":3957,"user":{"displayName":"Lalith Srinivas","userId":"11769043678043727988"}},"outputId":"296633f4-b777-453d-e7f8-e4e786d3b385"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.9.1)\n","Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.4.2)\n","Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2024.9.11)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.6)\n"]},{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n","[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Package stopwords is already up-to-date!\n","[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n","[nltk_data]   Package punkt_tab is already up-to-date!\n"]},{"output_type":"stream","name":"stdout","text":["[('language', 103), ('natural', 60), ('text', 53), ('processing', 47), ('nlp', 43), ('eg', 35), ('words', 32), ('semantic', 29), ('linguistics', 27), ('learning', 27)]\n"]}],"source":["!pip install nltk\n","import requests\n","from bs4 import BeautifulSoup\n","import nltk\n","from nltk.corpus import stopwords\n","from nltk.tokenize import word_tokenize\n","from collections import Counter\n","import string\n","\n","nltk.download('punkt')\n","nltk.download('stopwords')\n","nltk.download('punkt_tab')\n","\n","def fetch_text_from_url(url):\n","    \"\"\"\n","    Fetch text content from an online URL by parsing the HTML.\n","    \"\"\"\n","    response = requests.get(url)\n","    soup = BeautifulSoup(response.text, 'html.parser')\n","\n","    text = soup.get_text()\n","    return text\n","\n","def preprocess_text(text):\n","    \"\"\"\n","    Preprocess the text: remove punctuation, convert to lowercase, and tokenize.\n","    \"\"\"\n","\n","    text = text.translate(str.maketrans('', '', string.punctuation))\n","\n","    text = text.lower()\n","\n","\n","    tokens = word_tokenize(text)\n","\n","\n","    stop_words = set(stopwords.words('english'))\n","    tokens = [word for word in tokens if word not in stop_words]\n","\n","    return tokens\n","\n","def compute_word_frequency(url):\n","    \"\"\"\n","    Compute word frequency from an online text source.\n","    \"\"\"\n","    text = fetch_text_from_url(url)\n","\n","    tokens = preprocess_text(text)\n","    word_freq = Counter(tokens)\n","\n","    return word_freq\n","url = \"https://en.wikipedia.org/wiki/Natural_language_processing\"\n","word_frequency = compute_word_frequency(url)\n","\n","print(word_frequency.most_common(10))"]}],"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNO9Bv0oLOOdpOe4YRDtWOT"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}