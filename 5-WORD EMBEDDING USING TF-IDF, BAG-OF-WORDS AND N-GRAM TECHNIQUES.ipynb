{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPEAkUlyifxzH48EOjrHvAS"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jl0qUBo17_N4","executionInfo":{"status":"ok","timestamp":1731777267009,"user_tz":-330,"elapsed":1444,"user":{"displayName":"Lalith Srinivas","userId":"11769043678043727988"}},"outputId":"0d22045f-c561-4185-b2a5-99384edde5a2"},"outputs":[{"output_type":"stream","name":"stdout","text":["Bag-of-Words Vectors (Sparse Matrix):\n","[[0 0 0 0 0 1 1 0 0 1 1 0 1 0 0 0 1 0 0 0 0 0 0 0]\n"," [0 1 0 0 1 0 0 1 0 0 0 1 0 1 0 0 0 0 1 0 0 1 1 0]\n"," [1 1 1 1 0 0 0 0 1 0 0 0 0 0 1 1 0 1 0 1 1 0 0 1]]\n","Vocabulary: ['and' 'are' 'bag' 'but' 'embeddings' 'fascinating' 'field' 'for' 'idf'\n"," 'is' 'language' 'many' 'natural' 'nlp' 'of' 'powerful' 'processing'\n"," 'simple' 'tasks' 'techniques' 'tf' 'useful' 'word' 'words']\n","\n","TF-IDF Vectors (Sparse Matrix):\n","[[0.         0.         0.         0.         0.         0.40824829\n","  0.40824829 0.         0.         0.40824829 0.40824829 0.\n","  0.40824829 0.         0.         0.         0.40824829 0.\n","  0.         0.         0.         0.         0.         0.        ]\n"," [0.         0.27626457 0.         0.         0.36325471 0.\n","  0.         0.36325471 0.         0.         0.         0.36325471\n","  0.         0.36325471 0.         0.         0.         0.\n","  0.36325471 0.         0.         0.36325471 0.36325471 0.        ]\n"," [0.30746099 0.23383201 0.30746099 0.30746099 0.         0.\n","  0.         0.         0.30746099 0.         0.         0.\n","  0.         0.         0.30746099 0.30746099 0.         0.30746099\n","  0.         0.30746099 0.30746099 0.         0.         0.30746099]]\n","Vocabulary: ['and' 'are' 'bag' 'but' 'embeddings' 'fascinating' 'field' 'for' 'idf'\n"," 'is' 'language' 'many' 'natural' 'nlp' 'of' 'powerful' 'processing'\n"," 'simple' 'tasks' 'techniques' 'tf' 'useful' 'word' 'words']\n","\n","N-gram (Bigrams) Vectors (Sparse Matrix):\n","[[0 0 0 0 0 0 1 0 0 1 1 0 1 0 0 0 1 0 0 0 0 0]\n"," [0 0 1 0 0 1 0 1 0 0 0 1 0 1 0 0 0 0 0 1 1 0]\n"," [1 1 0 1 1 0 0 0 1 0 0 0 0 0 1 1 0 1 1 0 0 1]]\n","Vocabulary (Bigrams): ['and bag' 'are simple' 'are useful' 'bag of' 'but powerful'\n"," 'embeddings are' 'fascinating field' 'for many' 'idf and'\n"," 'is fascinating' 'language processing' 'many nlp' 'natural language'\n"," 'nlp tasks' 'of words' 'powerful techniques' 'processing is' 'simple but'\n"," 'tf idf' 'useful for' 'word embeddings' 'words are']\n"]}],"source":["from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n","\n","documents = [\n","    \"Natural Language Processing is a fascinating field.\",\n","    \"Word embeddings are useful for many NLP tasks.\",\n","    \"TF-IDF and Bag-of-Words are simple but powerful techniques.\"\n","]\n","\n","\n","bow_vectorizer = CountVectorizer()\n","bow_vectors = bow_vectorizer.fit_transform(documents)\n","\n","print(\"Bag-of-Words Vectors (Sparse Matrix):\")\n","print(bow_vectors.toarray())\n","print(\"Vocabulary:\", bow_vectorizer.get_feature_names_out())\n","\n","\n","tfidf_vectorizer = TfidfVectorizer()\n","tfidf_vectors = tfidf_vectorizer.fit_transform(documents)\n","\n","print(\"\\nTF-IDF Vectors (Sparse Matrix):\")\n","print(tfidf_vectors.toarray())\n","print(\"Vocabulary:\", tfidf_vectorizer.get_feature_names_out())\n","\n","\n","ngram_vectorizer = CountVectorizer(ngram_range=(2, 2))\n","ngram_vectors = ngram_vectorizer.fit_transform(documents)\n","\n","print(\"\\nN-gram (Bigrams) Vectors (Sparse Matrix):\")\n","print(ngram_vectors.toarray())\n","print(\"Vocabulary (Bigrams):\", ngram_vectorizer.get_feature_names_out())\n"]}]}