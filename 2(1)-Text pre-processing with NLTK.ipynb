{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPSSAWvoKltnPAuTwvE4x4g"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":[],"metadata":{"id":"FcoI4aaQtrc_","executionInfo":{"status":"ok","timestamp":1731772994320,"user_tz":-330,"elapsed":903,"user":{"displayName":"Lalith Srinivas","userId":"11769043678043727988"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fOqEtJkmsjLD","executionInfo":{"status":"ok","timestamp":1731773738459,"user_tz":-330,"elapsed":915,"user":{"displayName":"Lalith Srinivas","userId":"11769043678043727988"}},"outputId":"14ff59eb-bb39-43c6-df9d-5580060f2710"},"outputs":[{"output_type":"stream","name":"stdout","text":["Original Text:  NLTK is a leading platform for building Python programs to work with human language data.\n","Tokens:  ['nltk', 'leading', 'platform', 'building', 'python', 'programs', 'work', 'human', 'language', 'data']\n","Stemmed Tokens:  ['nltk', 'lead', 'platform', 'build', 'python', 'program', 'work', 'human', 'languag', 'data']\n","Lemmatized Tokens:  ['nltk', 'leading', 'platform', 'building', 'python', 'program', 'work', 'human', 'language', 'data']\n","Preprocessed Text:  nltk leading platform building python program work human language data\n"]},{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n","[nltk_data]   Package punkt_tab is already up-to-date!\n","[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Package stopwords is already up-to-date!\n","[nltk_data] Downloading package wordnet to /root/nltk_data...\n","[nltk_data]   Package wordnet is already up-to-date!\n"]}],"source":["import nltk\n","import string\n","from nltk.tokenize import word_tokenize\n","from nltk.corpus import stopwords\n","from nltk.stem import PorterStemmer, WordNetLemmatizer\n","\n","# Download necessary NLTK data files\n","# Download 'punkt_tab' instead of 'punkt'\n","nltk.download('punkt_tab')\n","nltk.download('stopwords')\n","nltk.download('wordnet')\n","\n","# Example text\n","text = \"NLTK is a leading platform for building Python programs to work with human language data.\"\n","\n","# 1. Tokenization\n","tokens = word_tokenize(text)\n","\n","# 2. Lowercasing\n","tokens = [token.lower() for token in tokens]\n","\n","# 3. Removing punctuation\n","tokens = [token for token in tokens if token not in string.punctuation]\n","\n","# 4. Removing stopwords\n","stop_words = set(stopwords.words('english'))\n","tokens = [token for token in tokens if token not in stop_words]\n","\n","# 5. Stemming\n","stemmer = PorterStemmer()\n","stemmed_tokens = [stemmer.stem(token) for token in tokens]\n","\n","# 6. Lemmatization\n","lemmatizer = WordNetLemmatizer()\n","lemmatized_tokens = [lemmatizer.lemmatize(token) for token in tokens]\n","\n","# 7. Remove extra whitespaces\n","preprocessed_text = ' '.join(lemmatized_tokens)\n","\n","# Results\n","print(\"Original Text: \", text)\n","print(\"Tokens: \", tokens)\n","print(\"Stemmed Tokens: \", stemmed_tokens)\n","print(\"Lemmatized Tokens: \", lemmatized_tokens)\n","print(\"Preprocessed Text: \", preprocessed_text)"]},{"cell_type":"code","source":[],"metadata":{"id":"_M0AIhIQtpt4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"2wrYa1oytquM"},"execution_count":null,"outputs":[]}]}